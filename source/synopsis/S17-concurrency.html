<!DOCTYPE html>
<html lang="ja">
<head>
<title>S17-concurrency</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" >
<link rel="stylesheet" href="http://yandex.st/highlightjs/8.0/styles/github.min.css">
<link rel="stylesheet" href="../default.css">
<script src="http://yandex.st/highlightjs/8.0/highlight.min.js"></script>
<script>hljs.configure( { languages: ['perl'] } ); hljs.initHighlightingOnLoad();</script>
</head>
<body class='pod'>
<!--
  generated by My::Pod v,
  using Pod::Simple::PullParser v3.28,
  under Perl v5.018002 at Sat Sep 27 10:05:33 2014 GMT.

 If you want to change this HTML document, you probably shouldn't do that
   by changing it directly.  Instead, see about changing the calling options
   to My::Pod, and/or subclassing My::Pod,
   then reconverting this document from the Pod source.
   When in doubt, email the author of My::Pod for advice.
   See 'perldoc My::Pod' for more info.

-->

<!-- start doc -->
<a name='___top' class='dummyTopAnchor' ></a>

<div class='indexgroup'>
<ul   class='indexList indexList1'>
  <li class='indexItem indexItem1'><a href='#TITLE'>TITLE</a>
  <li class='indexItem indexItem1'><a href='#AUTHORS'>AUTHORS</a>
  <li class='indexItem indexItem1'><a href='#VERSION'>VERSION</a>
  <li class='indexItem indexItem1'><a href='#Design_Philosophy'>Design Philosophy</a>
  <ul   class='indexList indexList2'>
    <li class='indexItem indexItem2'><a href='#Focus_on_composability'>Focus on composability</a>
    <li class='indexItem indexItem2'><a href='#Boundaries_between_synchronous_and_asynchronous_should_be_explicit'>Boundaries between synchronous and asynchronous should be explicit</a>
    <li class='indexItem indexItem2'><a href='#Implicit_parallelism_is_OK'>Implicit parallelism is OK</a>
    <li class='indexItem indexItem2'><a href='#Make_the_hard_things_possible'>Make the hard things possible</a>
  </ul>
  <li class='indexItem indexItem1'><a href='#Schedulers'>Schedulers</a>
  <li class='indexItem indexItem1'><a href='#Promises'>Promises</a>
  <li class='indexItem indexItem1'><a href='#Channels'>Channels</a>
  <li class='indexItem indexItem1'><a href='#Supplies'>Supplies</a>
  <li class='indexItem indexItem1'><a href='#System_events_exposed_as_Supplies'>System events exposed as Supplies</a>
  <li class='indexItem indexItem1'><a href='#I%2FO_features_exposed_as_Supplies'>I/O features exposed as Supplies</a>
  <li class='indexItem indexItem1'><a href='#Inter-Process_Communication_exposed_as_Promises_and_Supplies'>Inter-Process Communication exposed as Promises and Supplies</a>
  <li class='indexItem indexItem1'><a href='#The_Event_Loop'>The Event Loop</a>
  <ul   class='indexList indexList2'>
    <li class='indexItem indexItem2'><a href='#Threads'>Threads</a>
    <li class='indexItem indexItem2'><a href='#Atomic_Compare_and_Swap'>Atomic Compare and Swap</a>
  </ul>
  <li class='indexItem indexItem1'><a href='#Low-level_primitives'>Low-level primitives</a>
  <ul   class='indexList indexList2'>
    <li class='indexItem indexItem2'><a href='#Locks'>Locks</a>
    <li class='indexItem indexItem2'><a href='#Semaphore'>Semaphore</a>
  </ul>
</ul>
</div>

<h1><a class='u' href='#___top' title='click to go to top of document'
name="TITLE"
>TITLE</a></h1>

<p>Synopsis 17: Concurrency</p>

<h1><a class='u' href='#___top' title='click to go to top of document'
name="AUTHORS"
>AUTHORS</a></h1>

<pre><code>Jonathan Worthington &#60;jnthn@jnthn.net&#62;
Elizabeth Mattijsen &#60;liz@dijkmat.nl&#62;</code></pre>

<h1><a class='u' href='#___top' title='click to go to top of document'
name="VERSION"
>VERSION</a></h1>

<pre><code>Created: 3 Nov 2013

Last Modified: 18 May 2014
Version: 20</code></pre>

<p>This synopsis is based around the concurrency primitives and tools currently being implemented in Rakudo on MoarVM and the JVM. It covers both things that are already implemented today, in addition to things expected to be implemented in the near future (where &#34;near&#34; means O(months)).</p>

<h1><a class='u' href='#___top' title='click to go to top of document'
name="Design_Philosophy"
>Design Philosophy</a></h1>

<h2><a class='u' href='#___top' title='click to go to top of document'
name="Focus_on_composability"
>Focus on composability</a></h2>

<p>Perl 6 generally prefers constructs that compose well, enabling large problems to be solved by putting together solutions for lots of smaller problems. This also helps make it easier to extend and refactor code.</p>

<p>Many common language features related to parallel and asynchronous programming lack composability. For example:</p>

<ul>
<li>Locks do not compose, since two independently correct operations using locks may deadlock when performed together.</li>

<li>Callback-centric approaches tend to compose badly, with chains of asynchronous operations typically leading to deeply nested callbacks. This essentially is just leaving the programmer to do a CPS transform of their own logical view of the program by hand.</li>

<li>Directly spawning threads on a per-component basis tends to compose badly, as when a dozen such components are used together the result is a high number of threads with no ability to centrally schedule or handle errors.</li>
</ul>

<p>In Perl 6, concurrency features aimed at typical language users should have good composability properties, both with themselves and also with other language features.</p>

<h2><a class='u' href='#___top' title='click to go to top of document'
name="Boundaries_between_synchronous_and_asynchronous_should_be_explicit"
>Boundaries between synchronous and asynchronous should be explicit</a></h2>

<p>Asynchrony happens when we initiate an operation, then continue running our own idea of &#34;next thing&#34; without waiting for the operation to complete. This differs from synchronous programming, where calling a sub or method causes the caller to wait for a result for continuing.</p>

<p>The vast majority of programmers are much more comfortable with synchrony, as in many senses it&#39;s the &#34;normal thing&#34;. As soon as we have things taking place asynchronously, there is a need to coordinate the work, and doing so tends to be domain specific. Therefore, placing the programmer in an asynchronous situation when they didn&#39;t ask for it is likely to lead to confusion and bugs. We should try to make places where asynchrony happens clear.</p>

<p>It&#39;s also worthwhile trying to make it easy to keep asynchronous things flowing asynchronously. While synchronous code is pull-y (for example, eating its way through iterable things, blocking for results), asynchronous code is push-y (results get pushed to things that know what to do next).</p>

<p>Places where we go from synchronous to asynchronous, or from asynchronous to synchronous, are higher risk areas for bugs and potential bottlenecks. Thus, Perl 6 should try to provide features that help minimize the need to make such transitions.</p>

<h2><a class='u' href='#___top' title='click to go to top of document'
name="Implicit_parallelism_is_OK"
>Implicit parallelism is OK</a></h2>

<p>Parallelism is primarily about taking something we could do serially and using multiple CPU cores in order to get to a result more quickly. This leads to a very nice property: a parallel solution to a problem should give the same answer as a serial solution.</p>

<p>While under the hood there is asynchrony and the inherent coordination it requires, on the outside a problem solved using parallel programming is still, when taken as a whole, a single, synchronous operation.</p>

<p>Elsewhere in the specification, Perl 6 provides several features that allow the programmer to indicate that parallelizing an operation will produce the same result as evaluating it serially:</p>

<ul>
<li>Hyper operators (<a href="http://search.cpan.org/perldoc?S03#Hyper_operators" class="podlinkpod"
>&#34;Hyper operators&#34; in S03</a>) express that parallel operator application is safe.</li>

<li>Junctions (<a href="http://search.cpan.org/perldoc?S09#Junctions" class="podlinkpod"
>&#34;Junctions&#34; in S09</a>) may auto-thread in parallel.</li>

<li>Feeds (<a href="http://search.cpan.org/perldoc?S06#Feed_operators" class="podlinkpod"
>&#34;Feed operators&#34; in S06</a>) form pipelines and express that the stages may be executed in parallel in a producer-consumer style relationship (though each stage is in itself not parallelized).</li>

<li><code>hyper</code> and <code>race</code> list operators (<a href="http://search.cpan.org/perldoc?S02#The_hyper_operator" class="podlinkpod"
>&#34;The hyper operator&#34; in S02</a>) express that iteration may be done in parallel; this is a generalization of hyper operators.</li>
</ul>

<h2><a class='u' href='#___top' title='click to go to top of document'
name="Make_the_hard_things_possible"
>Make the hard things possible</a></h2>

<p>The easy things should be easy, and able to be built out of primitives that compose nicely. However, such things have to be built out of what VMs and operating systems provide: threads, atomic instructions (such as CAS), and concurrency control constructs such as mutexes and semaphores. Perl 6 is meant to last for decades, and the coming decades will doubtless bring new ways do do parallel and asynchronous programming that we do not have today. They will still, however, almost certainly need to be built out of what is available.</p>

<p>Thus, the primitive things should be provided for those who need to work on such hard things. Perl 6 should not hide the existence of OS-level threads, or fail to provide access to lower level concurrency control constructs. However, they should be clearly documented as <i>not</i> the way to solve the majority of problems.</p>

<h1><a class='u' href='#___top' title='click to go to top of document'
name="Schedulers"
>Schedulers</a></h1>

<p>Schedulers lie at the heart of all concurrency in Perl 6. While most users are unlikely to immediately encounter schedulers when starting to use Perl 6&#39;s concurrency features, many of them are implemented in terms of it. Thus, they will be described first here to avoid lots of forward references.</p>

<p>A scheduler is something that does the <code>Scheduler</code> role. Its responsibility is taking code objects representing tasks that need to be performed and making sure they get run, as well as handling any time-related operations (such as, &#34;run this code every second&#34;).</p>

<p>The current default scheduler is available as <code>$*SCHEDULER</code>. If no such dynamic variable has been declared, then <code>$PROCESS::SCHEDULER</code> is used. This defaults to an instance of <code>ThreadPoolScheduler</code>, which maintains a pool of threads and distributes scheduled work amongst them. Since the scheduler is dynamically scoped, this means that test scheduler modules can be developed that poke a <code>$*SCHEDULER</code> into <code>EXPORT</code>, and then provide the test writer with control over time.</p>

<p>The <code>cue</code> method takes a <code>Callable</code> object and schedules it.</p>

<pre><code>$*SCHEDULER.cue: { say &#34;Golly, I got scheduled!&#34; }</code></pre>

<p>Various options may be supplied as named arguments. (All references to time are taken to be in seconds, which may be fractional.) You may schedule an event to fire off after some number of seconds:</p>

<pre><code>$*SCHEDULER.cue: in=&#62;10, { say &#34;10s later&#34; }</code></pre>

<p>or at a given absolute time, specified as an <code>Instant</code>:</p>

<pre><code>$*SCHEDULER.cue: at=&#62;$instant, { say &#34;at $instant&#34; }</code></pre>

<p>If a scheduled item dies, the scheduler will catch this exception and pass it to a <code>handle_uncaught</code> method, a default implementation of which is provided by the <code>Scheduler</code> role. This by default will report the exception and cause the entire application to terminate. However, it is possible to replace this:</p>

<pre><code>$*SCHEDULER.uncaught_handler = sub ($exception) {
    $logger.log_error($exception);
}</code></pre>

<p>For more fine-grained handling, it is possible to schedule code along with a code object to be invoked with the thrown exception if it dies:</p>

<pre><code>$*SCHEDULER.cue:
    { upload_progress($stuff) },
    quit =&#62; -&#62; $ex { warn &#34;Could not upload latest progress&#34; }</code></pre>

<p>Use <code>:every</code> to schedule a task to run at a fixed interval, possibly with a delay before the first scheduling.</p>

<pre><code># Every second, from now
$*SCHEDULER.cue: :every(1), { say &#34;Oh wow, a kangaroo!&#34; };

# Every 0.5s, but don&#39;t start for 2s.
$*SCHEDULER.cue: { say &#34;Kenya believe it?&#34; }, :every(0.5), :in(2);</code></pre>

<p>Since this will cause the given to be executed for the given interval ad infinitum, there are two ways to make sure the scheduling of the task is halted at a future time. The first is provided by specifying the <code>:limit</code> parameter in the .cue:</p>

<pre><code># Every second, from now, but only 42 times
$*SCHEDULER.cue: :every(1), :limit(42), { say &#34;Oh wow, a kangaroo!&#34; };</code></pre>

<p>The second is by specifying a variable that will be checked at the end of each interval. The task will be stopped as soon as it has a True value. You can do this with the <code>:stop</code> parameter.</p>

<pre><code># Every second, from now, until stopped
my $stop;
$*SCHEDULER.cue: :every(1), :$stop, { say &#34;Oh wow, a kangaroo!&#34; };
sleep 10;
$stop = True;  # task stopped after 10 seconds</code></pre>

<p>Schedulers also provide counts of the number of operations in various states:</p>

<pre><code>say $*SCHEDULER.loads;</code></pre>

<p>This returns, in order, the number of cues that are not yet runnable due to delays, the number of cues that are runnable but not yet assigned to a thread, and the number of cues that are now assigned to a thread (and presumably running). [Conjecture: perhaps these should be separate methods.]</p>

<p>Schedulers may optionally provide further introspection in order to support tools such as debuggers.</p>

<p>There is also a <code>CurrentThreadScheduler</code>, which always schedules things on the current thread. It provides the same methods, just no concurrency, and any exceptions are thrown immediately. This is mostly useful for forcing synchrony in places that default to asynchrony. (Note that <code>.loads</code> can never return anything but 0 for the currently running cues, since they&#39;re waiting on the current thread to stop scheduling first!)</p>

<h1><a class='u' href='#___top' title='click to go to top of document'
name="Promises"
>Promises</a></h1>

<p>A <code>Promise</code> is a synchronization primitive for an asynchronous piece of work that will produce a single result (thus keeping the promise) or fail in some way (thus breaking the promise).</p>

<p>The simplest way to use a <code>Promise</code> is to create one:</p>

<pre><code>my $promise = Promise.new;</code></pre>

<p>And then later <code>keep</code> it:</p>

<pre><code>$promise.keep;      # True
$promise.keep(42);  # a specific return value for kept Promise</code></pre>

<p>Or <code>break</code> it:</p>

<pre><code>$promise.break;                             # False
$promise.break(X::Some::Problem.new);       # With exception
$promise.break(&#34;I just couldn&#39;t do it&#34;);    # With message</code></pre>

<p>The current status of a <code>Promise</code> is available through the <code>status</code> method, which returns an element from the <code>PromiseStatus</code> enumeration.</p>

<pre><code>enum PromiseStatus (:Planned(0), :Kept(1), :Broken(2));</code></pre>

<p>The result itself can be obtained by calling <code>result</code>. If the <code>Promise</code> was already kept, the result is immediately returned. If the <code>Promise</code> was broken then the exception that it was broken with is thrown. If the <code>Promise</code> is not yet kept or broken, then the caller will block until this happens.</p>

<p>A <code>Promise</code> will boolify to whether the <code>Promise</code> is already kept or broken. There is also an <code>excuse</code> method for extracting the exception from a <code>Broken</code> <code>Promise</code> rather than having it thrown.</p>

<pre><code>if $promise {
    if $promise.status == Kept {
        say &#34;Kept, result = &#34; ~ $promise.result;
    }
    else {
        say &#34;Broken because &#34; ~ $promise.excuse;
    }
}
else {
    say &#34;Still working!&#34;;
}</code></pre>

<p>You can also simply use a switch:</p>

<pre><code>given $promise.status {
    when Planned { say &#34;Still working!&#34; }
    when Kept    { say &#34;Kept, result = &#34;, $promise.result }
    when Broken  { say &#34;Broken because &#34;, $promise.excuse }
}</code></pre>

<p>There are various convenient &#34;factory&#34; methods on <code>Promise</code>. The most common is <code>start</code>.</p>

<pre><code>my $p = Promise.start(&#38;do_hard_calculation);</code></pre>

<p>This creates a <code>Promise</code> that runs the supplied code, and calls <code>keep</code> with its result. If the code throws an exception, then <code>break</code> is called with the <code>Exception</code>. Most of the time, however, the above is simply written as:</p>

<pre><code>my $p = start {
    # code here
}</code></pre>

<p>Which is implemented by calling <code>Promise.start</code>.</p>

<p>There is also a method to create a <code>Promise</code> that is kept after a number of seconds, or at a specific time:</p>

<pre><code>my $kept_in_10s      = Promise.in(10);
my $kept_in_duration = Promise.in($duration);
my $kept_at_instant  = Promise.at($instant);</code></pre>

<p>The <code>result</code> is always <code>True</code> and such a <code>Promise</code> can never be broken. It is mostly useful for combining with other promises.</p>

<p>There are also a couple of <code>Promise</code> combinators. The <code>anyof</code> combinator creates a <code>Promise</code> that is kept whenever any of the specified <code>Promise</code>s are kept. If the first promise to produce a result is instead broken, then the resulting <code>Promise</code> is also broken. The excuse is passed along. When the <code>Promise</code> is kept, it has a <code>True</code> result.</p>

<pre><code>my $calc     = start { ... }
my $timeout  = Promise.in(10);
my $timecalc = Promise.anyof($calc, $timeout);</code></pre>

<p>There is also an <code>allof</code> combinator, which creates a <code>Promise</code> that will be kept when all of the specified <code>Promise</code>s are kept, or broken if any of them are broken.</p>

<p>[Conjecture: there should be infix operators for these resembling the junctionals.]</p>

<p>The <code>then</code> method on a <code>Promise</code> is used to request that a certain piece of code should be run, receiving the <code>Promise</code> as an argument, when the <code>Promise</code> is kept or broken. If the <code>Promise</code> is already kept or broken, the code is scheduled immediately. It is possible to call <code>then</code> more than once, and each time it returns a <code>Promise</code> representing the completion of both the original <code>Promise</code> as well as the code specified in <code>then</code>.</p>

<pre><code>my $feedback_promise = $download_promise.then(-&#62; $res {
    given $res.status {
        when Kept   { say &#34;File $res.result().name() download&#34; }
        when Broken { say &#34;FAIL: $res.excuse()&#34;                 }
    }
});</code></pre>

<p>[Conjecture: this needs better syntax to separate the &#34;then&#34; policies from the &#34;else&#34; policies (and from &#34;catch&#34; policies?), and to avoid a bunch of switch boilerplate. We already know the givens here...]</p>

<p>One risk when working with <code>Promise</code> is that another piece of code will sneak in and keep or break a <code>Promise</code> it should not. The notion of a promise is user-facing. To instead represent the promise from the viewpoint of the promiser, the various built-in <code>Promise</code> factory methods and combinators use <code>Promise::Vow</code> objects to represent that internal resolve to fulfill the promise. (&#34;I have vowed to keep my promise to you.&#34;) The <code>vow</code> method on a <code>Promise</code> returns an object with <code>keep</code> and <code>break</code> methods. It can only be called once during a <code>Promise</code> object&#39;s lifetime. Since <code>keep</code> and <code>break</code> on the <code>Promise</code> itself just delegate to <code>self.vow.keep(...)</code> or <code>self.vow.break(...)</code>, obtaining the vow before letting the <code>Promise</code> escape to the outside world is a way to take ownership of the right to keep or break it. For example, here is how the <code>Promise.in</code> factory is implemented:</p>

<pre><code>method in(Promise:U: $seconds, :$scheduler = $*SCHEDULER) {
    my $p = Promise.new(:$scheduler);
    my $v = $p.vow;
    $scheduler.cue: { $v.keep(True) }, :in($seconds);
    $p;
}</code></pre>

<p>The <code>await</code> function is used to wait for one or more <code>Promise</code>s to produce a result.</p>

<pre><code>my ($a, $b) = await $p1, $p2;</code></pre>

<p>This simply calls <code>result</code> on each of the <code>Promise</code>s, so any exception will be thrown.</p>

<h1><a class='u' href='#___top' title='click to go to top of document'
name="Channels"
>Channels</a></h1>

<p>A <code>Channel</code> is essentially a concurrent queue. One or more threads can put values into the <code>Channel</code> using <code>send</code>:</p>

<pre><code>my $c = Channel.new;
$c.send($msg);</code></pre>

<p>Meanwhile, others can <code>receive</code> them:</p>

<pre><code>my $msg = $c.receive;</code></pre>

<p>Channels are ideal for producer/consumer scenarios, and since there can be many senders and many receivers, they adapt well to scaling certain pipeline stages out over multiple workers also. [Conjectural: The two feed operators <code>==&#62;</code> and <code>&#60;==</code> are implemented using Channel to connect each of the stages.]</p>

<p>A <code>Channel</code> may be &#34;forever&#34;, but it is possible to close it to further sends by telling it to <code>close</code>:</p>

<pre><code>$c.close();</code></pre>

<p>Trying to <code>send</code> any further messages on a closed channel will throw the <code>X::Channel::SendOnDone</code> exception. Closing a channel has no effect on the receiving end until all sent values have been received. At that point, any further calls to receive will throw <code>X::Channel::ReceiveOnDone</code>. The <code>done</code> method returns a <code>Promise</code> that is kept when a sender has called <code>close</code> and all sent messages have been received. Note that multiple calls to a channel return the same promise, not a new one.</p>

<p>While <code>receive</code> blocks until it can read, <code>poll</code> takes a message from the channel if one is there or immediately returns <code>Nil</code> if nothing is there.</p>

<p>There is also a <code>winner</code> statement [keywords still negotiable]:</p>

<pre><code>winner * {
    more $c1 { say &#34;First channel got a value&#34; }
    more $c2 { say &#34;Second channel got a value&#34; }
}</code></pre>

<p>That will invoke the closure associated with the first channel that receives a value.</p>

<p>It&#39;s possible to add a timer using the keyword <code>wait</code> followed by the number of seconds to wait (which may be fractional). As a degenerate case, in order to avoid blocking at all you may use a <code>wait 0</code>. The timeout is always checked last, to guarantee that the other entries are all tried at least once before timing out.</p>

<pre><code>my $gotone = winner * {
    more $c1 { say &#34;First channel got a value&#34; }
    more $c2 { say &#34;Second channel got a value&#34; }
    wait 0   { say &#34;Not done yet&#34;; Nil }
}</code></pre>

<p>The construct as a whole returns the result of whichever block was selected.</p>

<p>It&#39;s also possible to process a variadic list of channels together, using generic code that works over some set of the channels (use <code>*</code> to represent any of them). The index and the received value are passed to the code as named arguments <code>$:k</code> and &#60;$:v&#62; (possibly via priming if the code is instantiated ahead of time).</p>

<pre><code>winner * {
    more @channels { say &#34;Channel $:k received, result was: &#34;, $:v }
}</code></pre>

<p>In this case <code>$:k</code> returns the index of the channel, base 0. Likewise <code>$:v</code> returns the value.</p>

<p>The <code>winner</code> construct also automatically checks the <code>.done</code> promise corresponding to the channel, so it can also be used in order to write a loop to receive from a channel until it is closed:</p>

<pre><code>gather loop {
    winner $channel {
        more * { take $_ }
        done * { last }
    }
}</code></pre>

<p>This is such a common pattern that we make a channel in list context behave that way:</p>

<pre><code>for @$channel -&#62; $val { ... }
for $channel.list -&#62; $val { ... }</code></pre>

<p>(Note that this is not a combinator, but a means for transfering data from the reactive realm to the lazy realm. Some reasonable amount of buffering is assumed between the two.)</p>

<h1><a class='u' href='#___top' title='click to go to top of document'
name="Supplies"
>Supplies</a></h1>

<p>Channels are good for producer/consumer scenarios, but because each worker blocks on receive, it is not such an ideal construct for doing fine-grained processing of asynchronously produced streams of values. Additionally, there can only be one receiver for each value. Supplies exist to address both of these issues.</p>

<p>A <code>Supply</code> pushes or pumps values to one or more receivers who have registered their interest. There are two types of Supplies: <code>live</code> and <code>on demand</code>. When tapping into a <code>live</code> supply, the tap will only see values that are pumped <b>after</b> the tap has been created. Such supplies are normally infinite in nature, such as mouse movements. Closing the tap does not stop events from occurring, it just means nobody is listening. All tappers see the same stream. A tap on an <code>on demand</code> supply will initiate the production of values, and tapping the supply again may result in a new set of values. For example, <code>Supply.interval</code> produces a fresh timer with the appropriate interval each time it is tapped. If the tap is closed, the timer stops pushing out new values.</p>

<p>Anything that does the <code>Supply</code> role can be tapped (that is, subscribed to) by calling the <code>tap</code> method on it. This takes up to three callables as arguments, the optional ones expresses as named arguments:</p>

<pre><code>$supply.tap: -&#62; $value { say &#34;Got a $value&#34; },
    done =&#62; { say &#34;Reached the end&#34; },
    quit =&#62; {
        when X::FooBar { die &#34;Major oopsie&#34; };
        default        { warn &#34;Supply shut down early: $_&#34; }
    }</code></pre>

<p>The first, known as <code>more</code>, is invoked whenever a value is produced by the thing that has been tapped. The optional named parameter <code>done</code> specifies the code to be invoked when all expected values have been produced and no more will be. The optional named parameter <code>quit</code> specifies the code to be invoked if there is an error. This also means there will be no further values.</p>

<p>The simplest Supply is a <code>Supply</code> class, which is punned from the role. It creates a <code>live</code> supply. On the &#34;pumping&#34; end, this has corresponding methods <code>more</code>, <code>done</code>, and <code>quit</code>, which notify all current taps.</p>

<pre><code>my $s = Supply.new;

my $t1 = $s.tap({ say $_ });
$s.more(1);                              # 1\n
$s.more(2);                              # 2\n

my $t2 = $s.tap({ say 2 * $_ },
                { say &#34;End&#34; });
$s.more(3);                              # 3\n6\n</code></pre>

<p>The object returned by <code>tap</code> represents the subscription. To stop subscribing, call <code>close</code> on it.</p>

<pre><code>$t1.close;
$s.more(4);                              # 8\n
$s.done;                                 # End\n</code></pre>

<p>This doesn&#39;t introduce any asynchrony directly. However, it is possible for values to be pumped into a <code>Supply</code> from an asynchronous worker. In fact, it is possible for many threads to safely pump values into a supply. In the event this happens, the callback to more may be executed on many threads at the same time.</p>

<p>The <code>Supply</code> class has various methods that produce more interesting kinds of <code>Supply</code>. These default to working asynchronously.</p>

<p><code>Supply.for</code> takes a (potentially lazy) list of values, and returns an on demand <code>Supply</code> that, when tapped, will iterate over the values and invoke the <code>more</code> callable for each of them, and any <code>done</code> callable at the end. If the iteration at some point produces an exception, then the <code>quit</code> callable will be invoked to pass along the exception.</p>

<p><code>Supply.interval</code> produces an on demand <code>Supply</code> that, when tapped, will produce an ascending value at a regular time interval.</p>

<pre><code>Supply.interval(1).tap(&#38;say);     # Once a second, starting now
Supply.interval(5, 10).tap(&#38;say); # Each 5 seconds, starting in 10 seconds</code></pre>

<p>Take the returned tap object and close it to stop the ticks:</p>

<pre><code>my $t = Supply.interval(1).tap(&#38;say);
# ...later...
$t.close();</code></pre>

<p>[TODO: many more of these.]</p>

<p>Supplies are mathematically dual to iterators, and so it is possible to define the same set of operations on them as are available on lazy lists. The key difference is that, while <code>grep</code> on a lazy list <i>pulls</i> a value to process, working synchronously, <code>grep</code> on a Supply has values <i>pushed</i> through it, and pushes those that match the filter onwards to anything that taps it.</p>

<p>The following methods are available on an instantiated <code>Supply</code> (<code>$s</code> in these examples):</p>

<dl>
<dt><a name="list"
>list</a></dt>

<dd>
<pre><code>  my @l := $s.list;</code></pre>

<p>Produces a lazy <code>List</code> with the values of the <code>Supply</code>.</p>

<dt><a name="wait"
>wait</a></dt>

<dd>
<pre><code>  $s.wait;</code></pre>

<p>Waits until the specified <code>Supply</code> is <code>done</code> or <code>quit</code>.</p>

<dt><a name="Channel"
>Channel</a></dt>

<dd>
<pre><code>  my $c = $s.Channel;</code></pre>

<p>Produces a <code>Channel</code> of the values of the given <code>Supply</code>.</p>

<dt><a name="Promise"
>Promise</a></dt>

<dd>
<pre><code>  my $p = $s.Promise;</code></pre>

<p>Produces a <code>Promise</code> that will kept for the next value of the given <code>Supply</code>, or will be broken when the <code>Supply</code> is done before a value is produced.</p>

<dt><a name="last"
>last</a></dt>

<dd>
<pre><code>  my $l = $s.last(42);  # default: 1</code></pre>

<p>Produces a <code>Supply</code> that will only <code>more</code> the <b>last</b> given number (default 1) <code>more</code>&#39;s of the given <code>Supply</code> when it is <code>done</code>.</p>

<dt><a name="grab"
>grab</a></dt>

<dd>
<pre><code>  my $g = $s.grab( { .sort } ); # sort the values of a Supply</code></pre>

<p>Produces a <code>Supply</code> will grab all <code>more</code>&#39;s of the given <code>Supply</code> until it is done. It will then call the given closure and then <code>more</code> each of the return values of the closure, and then <code>done</code> the Supply that was produced.</p>

<dt><a name="flat"
>flat</a></dt>

<dd>
<pre><code>  my $f = $s.flat;</code></pre>

<p>Produces a <code>Supply</code> in which all values of the original supply are flattened.</p>

<dt><a name="do"
>do</a></dt>

<dd>
<pre><code>  my $seen;
  my $d = $s.do( {$seen++} );</code></pre>

<p>Produces a <code>Supply</code> that is identical to the original supply, but will execute the given code for its side-effects. It promises that only one thread will ever be executing the code object passed to it at a time; others will block behind it.</p>

<dt><a name="act"
>act</a></dt>

<dd>
<pre><code>  my $seen;
  $s-&#62;act( {$seen++} );</code></pre>

<p>A special case of <code>Supply</code>.do, that will also create a tap on the given <code>Supply</code>, so that you only need to worry about writing the side-effect code.</p>

<dt><a name="grep"
>grep</a></dt>

<dd>
<pre><code>  my $g = $s.grep( * &#62; 5 );
  my $g = $s.grep(Int);</code></pre>

<p>Produces a <code>Supply</code> that only provides values that you want. Takes either a <code>Callable</code> (which is supposed to return a <code>True</code> value to pass on <code>more</code>&#39;d values) or a value to be smartmatched against.</p>

<dt><a name="map"
>map</a></dt>

<dd>
<pre><code>  my $m = $s.map( * * 5 );</code></pre>

<p>Produces a <code>Supply</code> that provides its original&#39;s Supply values multiplied by 5.</p>

<pre><code>  my $m2 = $s.map( { $_ xx 2 } );</code></pre>

<p>Produces a <code>Supply</code> that provides its original&#39;s Supply values twice.</p>

<dt><a name="uniq"
>uniq</a></dt>

<dd>
<pre><code>  my $u = $s.uniq( :as( {$_} ), :with( &#38;[===] ), :expires(1) );</code></pre>

<p>Produces a <code>Supply</code> that only provides unique values, as defined by the optional <code>as</code> and <code>with</code> named parameters (same as <a href="http://search.cpan.org/perldoc?List.uniq" class="podlinkpod"
>List.uniq</a>). The optional <code>expires</code> parameter specifies how long to wait (in seconds) before &#34;resetting&#34; and not considering a value to have been seen, even if it&#39;s the same as an old value.</p>

<dt><a name="squish"
>squish</a></dt>

<dd>
<pre><code>  my $q = $s.squish( :as( {$_} ), :with( &#38;[===] ), :expires(1) );</code></pre>

<p>Produces a <code>Supply</code> that only provides sequentially different values, as defined by the optional <code>as</code> and <code>with</code> named parameters (same as <a href="http://search.cpan.org/perldoc?List.squish" class="podlinkpod"
>List.squish</a>). The optional <code>expires</code> parameter specifies how long to wait (in seconds) before &#34;resetting&#34; and not squishing a new value with an old one, even if they are the same.</p>

<dt><a name="max"
>max</a></dt>

<dd>
<pre><code>  my $a = $s.max(&#38;by); # default &#38;infix:&#60;cmp&#62;</code></pre>

<p>Produces a <code>Supply</code> that produces the <b>maximum</b> values of the specified <code>Supply</code>. In other words, from a continuously ascending <code>Supply</code> it will produce all the values. From a continuously descending <code>Supply</code> it will only produce the first value. The optional parameter specifies the comparator, just as with <code>Any.max</code>.</p>

<dt><a name="min"
>min</a></dt>

<dd>
<pre><code>  my $i = $s.min(&#38;by); # default &#38;infix:&#60;cmp&#62;</code></pre>

<p>Produces a <code>Supply</code> that produces the <b>minimum</b> values of the specified <code>Supply</code>. In other words, from a continuously descending <code>Supply</code> it will produce all the values. From a continuously ascending <code>Supply</code> it will only produce the first value. The optional parameter specifies the comparator, just as with <code>Any.min</code>.</p>

<dt><a name="minmax"
>minmax</a></dt>

<dd>
<pre><code>  my $m = $s.minmax(&#38;by); # default &#38;infix:&#60;cmp&#62;</code></pre>

<p>Produces a <code>Supply</code> that produces the <code>Range</code>s with the <b>minimum</b> and <b>maximum</b> values of the specified <code>Supply</code>. The optional parameter specifies the comparator, just as with <code>Any.minmax</code>.</p>

<dt><a name="batch"
>batch</a></dt>

<dd>
<pre><code>  my $b = $s.batch( :elems(100), :seconds(1) );</code></pre>

<p>Produces a <code>Supply</code> that batches the values of the given Supply by either the number of elements (using the <code>elems</code> named parameter) or the maximum number of seconds (using the <code>seconds</code> named parameter) or both. Values are grouped in a single array element when flushed.</p>

<dt><a name="elems"
>elems</a></dt>

<dd>
<pre><code>  my $e = $s.elems($seconds?); # default: see all</code></pre>

<p>Produces a <code>Supply</code> that produces the number of elements seen in the given <code>Supply</code>. You can also specify an interval to only see the number of elements seen once per that interval.</p>

<dt><a name="rotor"
>rotor</a></dt>

<dd>
<pre><code>  my $b = $s.rotor( $elems, $overlap );

  my $b = $s.rotor;    # elems = 2, overlap = 1</code></pre>

<p>Produces a &#34;rotoring&#34; <code>Supply</code> where every <code>elems</code> number of elements are combined, and the last <code>overlap</code> elements of such a combination become the initial elements of the next combination. This can e.g. be used to convert a <code>Supply</code> of coordinates into a <code>Supply</code> of begin/end points.</p>

<dt><a name="delayed"
>delayed</a></dt>

<dd>
<pre><code>  my $d = $s.delayed( 3.5 );  # delay supply 3.5 seconds</code></pre>

<p>Produces a <code>Supply</code> that passes on the values of the given Supply with the given delay (in seconds).</p>

<dt><a name="stable"
>stable</a></dt>

<dd>
<pre><code>  my $u = $s.stable( $seconds, :$scheduler );</code></pre>

<p>Produces a <code>Supply</code> that only passes on a value if it wasn&#39;t superseded by another value in the given time (in seconds). Optionally uses another scheduler than the default scheduler, using the <code>scheduler</code> named parameter.</p>

<dt><a name="start"
>start</a></dt>

<dd>
<pre><code>  my $t = $s.start( {...} );</code></pre>

<p>Takes a closure and, for each supplied value, schedules the closure to run on another thread. It then more&#39;s a Supply (resulting in us having a supply of supplies) that will either have a single value more&#39;d and then be done if the async work completes successfully, or quit if the work fails. Useful for kicking off work on the thread pool if you do not want to block up the thread pushing values at you (maybe &#39;cus you are reacting to UI events, but have some long-running work to kick off). Usually used in combination with <code>migrate</code>.</p>

<dt><a name="migrate"
>migrate</a></dt>

<dd>
<pre><code>  my $m = $t.migrate;</code></pre>

<p>Produces a continuous <code>Supply</code> from a <code>Supply</code>, in which each value is a <code>Supply</code>. As soon a new <code>Supply</code> appears, it will close the current <code>Supply</code> and provide values from the new <code>Supply</code>. Can be used in combination with <code>schedule_on</code>.</p>

<dt><a name="schedule_on"
>schedule_on</a></dt>

<dd>
<pre><code>  my $o = $m.schedule_on( $scheduler );</code></pre>

<p>This allows a <code>Supply</code>&#39;s more/done/quit to be scheduled on another scheduler. Useful in GUI situations, for example, where the final stage of some work needs to be done on some UI scheduler in order to have UI updates run on the UI thread.</p>

<dt><a name="reduce"
>reduce</a></dt>

<dd>
<pre><code>  my $r = $s.reduce( {...} );</code></pre>

<p>Produces a <code>Supply</code> that will <code>more</code> each reduction from the given <code>Supply</code>, just like <code>reduce</code> on <code>List</code>s.</p>

<dt><a name="lines"
>lines</a></dt>

<dd>
<pre><code>  my $l = $s.lines;              # chomp lines
  my $l = $s.lines( :!chomp );   # do *not* chomp lines</code></pre>

<p>Produces a <code>Supply</code> that will <code>more</code> the characters coming in line by line from a <code>Supply</code> that usually created by some asynchronous I/O operation. The optional <code>:chomp</code> named parameter indicates whether to remove line separators: the default is <code>True</code>.</p>

<dt><a name="words"
>words</a></dt>

<dd>
<pre><code>  my $w = $s.words;</code></pre>

<p>Produces a <code>Supply</code> that will <code>more</code> the characters coming in word by word from a <code>Supply</code> that usually created by some asynchronous I/O operation.</p>

<dt><a name="classify"
>classify</a></dt>

<dd>
<pre><code>  my $c = $s.classify( {.WHAT} );  # one Supply per type of value
  my $h = $s.classify( %mapper );
  my $a = $s.classify( @mapper );</code></pre>

<p>Produces a <code>Supply</code> in which the <code>more</code>&#39;d values are <code>Pair</code>s consisting of the classification value and the <code>Supply</code> to which values of the given <code>Supply</code> will be <code>more</code>d. Similar to <code>List.classify</code>, but does not support multi-level classification.</p>

<dt><a name="categorize"
>categorize</a></dt>

<dd>
<pre><code>  my $c = $s.categorize( {@categories} );
  my $h = $s.categorize( %mapper );
  my $a = $s.categorize( @mapper );</code></pre>

<p>Produces a <code>Supply</code> in which the <code>more</code>&#39;d values are <code>Pair</code>s consisting of zero or more classification values and the <code>Supply</code> to which values of the given <code>Supply</code> will be <code>more</code>d. Similar to <code>List.categorize</code>.</p>

<dt><a name="reverse"
>reverse</a></dt>

<dd>
<pre><code>  my $r = $s.reverse;</code></pre>

<p>Produces a <code>Supply</code> with the <code>more</code>&#39;s of the given Supply in reverse order. Please note that this <code>Supply</code> will only start delivering values as soon as the given <code>Supply</code> is <code>done</code>.</p>

<dt><a name="sort"
>sort</a></dt>

<dd>
<pre><code>  my $o = $s.sort(&#38;by);  # default &#38;infix:&#60;cmp&#62;</code></pre>

<p>Produces a <code>Supply</code> with the <code>more</code>&#39;s of the given Supply in sorted order. Please note that this <code>Supply</code> will only start delivering values as soon as the given <code>Supply</code> is <code>done</code>. Optionally accepts a comparator <code>Block</code>.</p>
</dd>
</dl>

<p>There are some combinators that deal with bringing multiple supplies together:</p>

<dl>
<dt><a name="merge"
><code>merge</code></a></dt>

<dd>
<pre><code>  my $m = $s1.merge($s2);

  my $m = Supply.merge(@s);  # also as class method</code></pre>

<p>Produces a <code>Supply</code> containing the values produced by given and the specified supply or supplies, and triggering <code>done</code> once all of the supplies have done so.</p>

<dt><a name="zip"
><code>zip</code></a></dt>

<dd>
<pre><code>  my $z = $s1.zip($s2);                   # defaults to :with( &#38;[,] )

  my $z = Supply.zip(@s, :with( &#38;[,] ));  # also as class method</code></pre>

<p>Produces a <code>Supply</code> that pairs together items from the given and the specified supply or supplies, using <code>infix:&#60;,&#62;</code> by default or any other user-supplied function with the <code>with</code> named parameter.</p>

<dt><a name="zip-latest"
><code>zip-latest</code></a></dt>

<dd>
<pre><code>  my $z = $s1.zip-latest($s2);                  # like zip, defaults to :with( &#38;[,] )

  my $z = Supply.zip-latest(@s, :with( &#38;[,] )); # also a method on Supply.

  my $z = Supply.zip-latest( @s, :initial(42,63) ); # initial state</code></pre>

<p>Produces a <code>Supply</code> that will emit tuples of values as soon as any combined Supply produces a value. Before any tuples are emitted, all supplies have to have produced at least one value. By default, it uses <code>infix:&#60;,&#62;</code> to produce the tuples, but the named parameter <code>with</code> can override that.</p>

<p>The named parameter <code>initial</code> can optionally be used to indicate the initial state of the values to be <code>more</code>d.</p>
</dd>
</dl>

<p>[TODO: plenty more of these: while, until...]</p>

<p>These combinators that involve multiple supplies need care in their implementation, since values may arrive at any point on each, and possibly at the same time. To help write such combinators, the <code>on</code> meta-combinator is useful. <code>on</code> taps many supplies, and ensures that only <b>one</b> callback will be running at a time, freeing the combinator writer of worrying about synchronization issues.</p>

<p>The <code>on</code> combinator takes a block that receives the <code>Supply</code> it will generate (and return) as the parameter. That block is supposed to return list of <code>Pairs</code>, in which the keys are one or more Supplies. And the values are either a <code>Block</code> (to be called for each value for that <code>Supply</code>), or a hash with Pairs for <code>more</code>, <code>done</code> and <code>quit</code>.</p>

<p>A simple combinator for <code>Pair</code>ing values from two Supplies ($a and $b), would look like this:</p>

<pre><code>  my $result = on -&#62; $res {
  my @as;
  my @bs;
  on -&#62; $res {
      $a =&#62; sub ($val) {
          @as.push($val);
          if @as &#38;&#38; @bs {
              $res.more( @as.shift =&#62; @bs.shift );
          }
      },
      $b =&#62; sub ($val) {
          @bs.push($val);
          if @as &#38;&#38; @bs {
              $res.more( @as.shift =&#62; @bs.shift );
          }
      }
  }
  }</code></pre>

<p>Thus there is never any race or other thread-safely problems with mutating the <code>@as</code> and <code>@bs</code>. The default behaviour, if a <code>Callable</code> is specified along with the supply, is to use it for <code>more</code> and provide a default <code>done</code> and <code>quit</code>. The default <code>done</code> triggers <code>done</code> on the result <code>Supply</code>.</p>

<p>Note that the code blocks for both Supplies are identical. There must be a better way of doing this. And indeed, there is: you can also specify more than one <code>Supply</code> per block. The same as above implemented using that:</p>

<pre><code>  my $result = on -&#62; $res {
  my @values = ([],[]);
  ($a,$b) =&#62; sub ($val,$index) {
      @values[$index].push($val);
      if all(@values) {
          $res.more( (@values&#62;&#62;.shift) );
      }
  }
  }</code></pre>

<p>Note that the block that is being called for each value from any of the Supplies also receives an index value to be able to group the values received. By default, any <code>done</code> or <code>quit</code> will be immediately propagated. This is basically how <code>zip</code> is implemented.</p>

<p>Sometimes, we want the resulting <code>Supply</code> to be <code>done</code> only when all specified Supplies are done. This is possible by specifying a hash with keys for <code>more</code>, <code>done</code> and/or <code>quit</code>, instead of just a <code>Callable</code>. Given an array @s with Supplies:</p>

<pre><code>  my $done = 0;
  my $result = on -&#62; $res {
  @s =&#62; {
      more =&#62; -&#62; \val { $res.more(val) },
      done =&#62; { $res.done if ++$done == +@s }
  }
  }</code></pre>

<p>This is essentially how <code>merge</code> is implemented. Note that if we don&#39;t need the index (as indicated by its absence in the signature of the <code>Callable</code>s), it will not be passed.</p>

<p>A <code>quit</code> handler can be provided in a similar way, although the default - convey the failure to the result supply - is normally what is wanted. The exception is writing combinators related to error handling.</p>

<h1><a class='u' href='#___top' title='click to go to top of document'
name="System_events_exposed_as_Supplies"
>System events exposed as Supplies</a></h1>

<p>System events, such as signals, or mouse events, can be exposed as Supplies. Because of lack of portability, these will most likely be implemented as third-party modules.</p>

<p>Basic signal support is offered by the <code>signal</code> function, which takes one or more <code>Signal</code> enums, and an optional <code>scheduler</code> named parameter. It produces a <code>Supply</code> which, when tapped, will <code>more</code> any signal coming in. For example:</p>

<pre><code>  signal(SIGINT).tap( { say &#34;Thank you for your attention&#34;; exit 0 } );</code></pre>

<p>would catch Control-C, thank you, and then exit. Of course, you don&#39;t need to exit immediately. Here&#39;s an example of how you would make sure that an iteration in a loop is completed before exiting:</p>

<pre><code>  for @todo {
  state $quitting;
  state $tap = signal(SIGINT).tap( { $quitting = True } );
  LAST  $tap.close;
  LEAVE exit(0) if $quitting;
  ... # code to protect
  }</code></pre>

<p>This probably could use some syntactic sugar.</p>

<p>The list of supported <code>Signals</code> can be found by checking <code>Signal::.keys</code>, as you would any enum.</p>

<h1><a class='u' href='#___top' title='click to go to top of document'
name="I/O_features_exposed_as_Supplies"
>I/O features exposed as Supplies</a></h1>

<p>Various I/O-related things are also exposed as supplies. For example, it is possible to get notifications on changes to files or files (directly) in a directory, using:</p>

<pre><code>IO::Notification.watch_path(&#34;.&#34;).tap(-&#62; $file {
    say &#34;$file changed&#34;;
});</code></pre>

<p>This is quite a mouthful, so there is a shortcut available with the <code>IO</code> coercer and the <code>watch</code> method:</p>

<pre><code>&#34;.&#34;.IO.watch.tap: -&#62; $file { say &#34;$file changed&#34; };</code></pre>

<p>Note that since I/O callbacks are, by default, scheduled on the thread pool, then it&#39;s possible that your callback will be executing twice on the same thread. One way to cope is with <code>do</code>, and then a tap at the end:</p>

<pre><code>&#34;.&#34;.IO.watch.do(-&#62; $file {
    state %changes;
    say &#34;$file changed (change {++%changes{$file}})&#34;;
}).tap();</code></pre>

<p>Here, we are tapping it purely for the side-effects, and <code>do</code> promises we will only be in that code block one thread at a time. To make this more convenient, there is also shortcut with the <code>act</code> method:</p>

<pre><code>&#34;.&#34;.IO.watch.act(-&#62; $file {
    state %changes;
    say &#34;$file changed (change {++%changes{$file}})&#34;;
});</code></pre>

<p>It can also take <code>done</code> and <code>quit</code> named parameters; these go to the tap, while the <code>more</code> closure is put in a <code>do</code>. A <code>Tap</code> is returned, which may be closed in the usual way. (Note that the name <code>act</code> is also a subtle reference to actor semantics.)</p>

<h1><a class='u' href='#___top' title='click to go to top of document'
name="Inter-Process_Communication_exposed_as_Promises_and_Supplies"
>Inter-Process Communication exposed as Promises and Supplies</a></h1>

<p>Starting external processes is rather easy: <code>shell()</code>, <code>run()</code> and <code>qx//</code>. Having external processes run asynchronously, is slightly more involved. But not much. The workhorse of asynchronous IPC in Perl 6 is <code>Proc::Async</code>:</p>

<pre><code>my $proc = Proc::Async.new( $path, @args );</code></pre>

<p>If you like to <b>send</b> data to the process, you need to open it with the <code>:w</code> named parameter.</p>

<pre><code>my $proc = Proc::Async.new( $path, @args, :w );</code></pre>

<p>By default, the current environment (as available in <code>%*ENV</code>) will be set for the external process. You can override this with the :ENV named parameter:</p>

<pre><code>my $proc = Proc::Async.new( $path, @args, :ENV(%hash) );</code></pre>

<p>The returned object can then be called whenever needed to start the external process. However, before you do that, one needs to be clear what to do about the output of the external process. Getting information back from the external process&#39;s <code>STDOUT</code> or <code>STDERR</code>, is done by a <code>Supply</code> that either gets characters or bytes.</p>

<pre><code>$proc.stdout.act(&#38;say);   # simply pass it on to our $*OUT as chars
$proc.stderr.act(&#38;note);  # and $*ERR as chars, but could be any code</code></pre>

<p>or:</p>

<pre><code>$proc.stdout(:bin).act: { # process STDOUT bytes };
$proc.stderr(:bin).act: { # process STDERR bytes };</code></pre>

<p>So, to make sure no information will be lost, you need to create and tap the supplies <b>before</b> the process is started.</p>

<p>To start the external process, you need to call the <code>.start</code> method. It returns a <code>Promise</code> that becomes <code>Kept</code> (and True) if the process concludes successfully, or <code>Broken</code> (and False) if the process failed for some reason.</p>

<pre><code>my $done = $proc.start( :$scheduler = $*SCHEDULER );</code></pre>

<p>To send data to the running process, you can use the <code>.print</code>, <code>.say</code> and <code>.write</code> methods on the <code>Proc::Async</code> object:</p>

<pre><code>my $printed = $proc.print( &#34;Hello world\n&#34;, :$scheduler = $*SCHEDULER );
my $said    = $proc.say(   &#34;Hello world&#34;,   :$scheduler = $*SCHEDULER );
my $written = $proc.write( $buffer,         :$scheduler = $*SCHEDULER );</code></pre>

<p>They all also return a <code>Promise</code> that is <code>Kept</code> when communication with the process was successful.</p>

<p>Some programs expect their <code>STDIN</code> to be closed to signify the end of their processing. This can be achieved with the <code>.close-stdin</code> method:</p>

<pre><code>$proc.close-stdin;</code></pre>

<p>Finally, if your process as going awry, you can stop it with the <code>.kill</code> method:</p>

<pre><code>$proc.kill;            # sends HUP signal to process
$proc.kill(&#34;SIGINT&#34;);  # send INT signal
$proc.kill(1);         # if you just know the signal number on your system</code></pre>

<p>The parameter should be something that is acceptable to the Kernel.signal method.</p>

<h1><a class='u' href='#___top' title='click to go to top of document'
name="The_Event_Loop"
>The Event Loop</a></h1>

<p>There is no event loop. Previous versions of this synopsis mentioned an event loop that would be underlying all concurrency. In this version, this is not the case.</p>

<h2><a class='u' href='#___top' title='click to go to top of document'
name="Threads"
>Threads</a></h2>

<p>VM-level threads, which typically correspond to OS-level threads, are exposed through the <code>Thread</code> class. Whatever underlies it, a <code>Thread</code> should always be backed by something that is capable of being scheduled on a CPU core (that is, it may <i>not</i> be a &#34;green thread&#34; or similar). Most users will not need to work with <code>Thread</code>s directly. However, those building their own schedulers may well need to do so, and there may be other exceptional circumstances that demand such low-level control.</p>

<p>The easiest way to start a thread is with the <code>start</code> method, which takes a <code>Callable</code> and runs it on a new thread:</p>

<pre><code>my $thread = Thread.start({
    say &#34;Gosh, I&#39;m in a thread!&#34;;
});</code></pre>

<p>It is also possible to create a thread object, and set it running later:</p>

<pre><code>my $thread = Thread.new(code =&#62; {
    say &#34;A thread, you say?&#34;;
});
# later...
$thread.run();</code></pre>

<p>Both approaches result in <code>$thread</code> containing a <code>Thread</code> object. At some point, <code>finish</code> should be called on the thread, from the thread that started it. This blocks until the thread has completed.</p>

<pre><code>say &#34;Certainly before the thread is started&#34;;
my $thread = Thread.start({ say &#34;In the thread&#34; });
say &#34;This could come before or after the thread&#39;s output&#34;;
$thread.finish();
say &#34;Certainly after all the above output&#34;;</code></pre>

<p>As an alternative to <code>finish</code>, it is possible to create a thread whose lifetime is bounded by that of the overall application. Such threads are automatically terminated when the application exits. In a scenario where the initial thread creates an application lifetime thread and no others, then the exit of the initial thread will cause termination of the overall program. Such a thread is created by either:</p>

<pre><code>my $thread = Thread.new(:code({ ... }), :app_lifetime);</code></pre>

<p>Or just, by using the <code>start</code> method:</p>

<pre><code>my $thread = Thread.start({ ... }, :app_lifetime);</code></pre>

<p>The property can be introspected:</p>

<pre><code>say $thread.app_lifetime; # True/False</code></pre>

<p>Each thread also has a unique ID, which can be obtained by the <code>id</code> property.</p>

<pre><code>say $thread.id;</code></pre>

<p>This should be treated as an opaque number. It can not be assumed to map to any particular operating system&#39;s idea of thread ID, for example. For that, use something that lets you get at OS-level identifiers (such as calling an OS API using NativeCall).</p>

<p>A thread may also be given a name.</p>

<pre><code>my $thread = Thread.start({ ... }, :name&#60;Background CPU Eater&#62;);</code></pre>

<p>This can be useful for understanding its usage. Uniqueness is not enforced; indeed, the default is &#34;&#60;anon&#62;&#34;.</p>

<p>A thread stringifies to something of the form:</p>

<pre><code>Thread&#60;id&#62;(name)</code></pre>

<p>For example:</p>

<pre><code>Thread&#60;1234&#62;(&#60;anon&#62;)</code></pre>

<p>The currently executing thread is available through <code>$*THREAD</code>. This is even available in the initial thread of the program, in this case by falling back to <code>$PROCESS::THREAD</code>, which is the initial thread of the process.</p>

<p>Finally, the <code>yield</code> method can be called on <code>Thread</code> (not on any particular thread) to hint to the OS that the thread has nothing useful to do for the moment, and so another thread should run instead.</p>

<h2><a class='u' href='#___top' title='click to go to top of document'
name="Atomic_Compare_and_Swap"
>Atomic Compare and Swap</a></h2>

<p>The Atomic Compare and Swap (CAS) primitive is directly supported by most modern hardware. It has been shown that it can be used to build a whole range of concurrency control mechanisms (such as mutexes and semaphores). It can also be used to implement lock-free data structures. It is decidedly a primitive, and not truly composable due to risk of livelock. However, since so much can be built out of it, Perl 6 provides it directly.</p>

<p>A Perl 6 implementation of CAS would look something like this:</p>

<pre><code>sub cas($ref is rw, $expected, $new) {
    my $seen = $ref;
    if $ref === $expected {
        $ref = $new;
    }
    return $seen;
}</code></pre>

<p>Except that it happens atomically. For example, a crappy non-reentrant mutex could be implemented as:</p>

<pre><code>class CrappyMutex {
    has $!locked = 0;
    
    method lock() {
        loop {
            return if cas($!locked, 0, 1) == 0;
        }
    }
    
    method unlock() {
        $!locked = 0;
    }
}</code></pre>

<p>Another common use of CAS is in providing lock-free data structures. Any data structure can be made lock-free as long as you&#39;re willing to never mutate it, but build a fresh one each time. To support this, there is another <code>&#38;cas</code> candidate that takes a scalar and a block. It calls the block with the seen initial value. The block returns the new, updated value. If nothing else updated the value in the meantime, the reference will be updated. If the CAS fails because another update got in first, the block will be run again, passing in the latest value.</p>

<p>So, atomically incrementing a variable is done thusly:</p>

<pre><code>cas $a, { $_.succ };    # $a++</code></pre>

<p>or more generally for all assignment meta-operators:</p>

<pre><code>cas $a, { $_ * 5 };     # $a *= 5</code></pre>

<p>Another example, implementing a top-5 news headlines list to be accessed and updated without ever locking, as:</p>

<pre><code>class TopHeadlines {
    has $!headlines = [];   # Scalar holding array, as CAS needs
    
    method headlines() {
        $!headlines
    }
    
    method add_headline($headline) {
        cas($!headlines, -&#62; @current {
            my @new = $headline, @current;
            @new.pop while @new.elems &#62; 5;
            @new
        });
    }
}</code></pre>

<p>It&#39;s the programmer&#39;s duty to ensure that the original data structure is never mutated and that the block has no side-effects (since it may be run any number of times).</p>

<h1><a class='u' href='#___top' title='click to go to top of document'
name="Low-level_primitives"
>Low-level primitives</a></h1>

<p>Perl6 offers high-level concurrency methods, but in extreme cases, like if you need to implement a fundamentally different mechanism, these primitives are available.</p>

<h2><a class='u' href='#___top' title='click to go to top of document'
name="Locks"
>Locks</a></h2>

<p>Locks are unpleasant to work with, and users are pushed towards higher level synchronization primitives. However, those need to be implemented via lower level constructs for efficiency. As such, a simple lock mechanism - as close to what the execution environment offers as possible - is provided by the <code>Lock</code> class. Note that it is erroneous to rely on the exact representation of an instance of this type (for example, don&#39;t assume it can be mixed into). Put another way, treat <code>Lock</code> like a native type.</p>

<p>A <code>Lock</code> is instantiated with <code>new</code>:</p>

<pre><code>$!lock = Lock.new;</code></pre>

<p>The best way to use it is:</p>

<pre><code>$!lock.protect: {
    # code to run with the lock held
}</code></pre>

<p>This acquires the lock, runs the code passed, and then releases the lock. It ensures the lock will be released even if an exception is thrown. It is also possible to do:</p>

<pre><code>{
    $!lock.lock();
    # do stuff
    LEAVE $!lock.unlock()
}</code></pre>

<p>When using the <code>lock</code> and <code>unlock</code> methods, the programmer must ensure that the lock is unlocked. <code>Lock</code> is reentrant. Naturally, it&#39;s easy to introduce deadlocks. Again, this is a last resort, intended for those who are building first resorts.</p>

<h2><a class='u' href='#___top' title='click to go to top of document'
name="Semaphore"
>Semaphore</a></h2>

<p>The <code>Semaphore</code> class implements traditional semaphores that can be initiated with a fixed number of permits and offers the operations <code>acquire</code> to block on a positive number of permits to become available and then reduce that number by one, <code>tryacquire</code> to try to acquire a permit, but return <code>False</code> instead of blocking if there are no permits available yet. The last operation is <code>release</code>, which will increase the number of permits by one.</p>

<p>The initial number of permits may be negative, positive or 0.</p>

<p>Some implementations allow for race-free acquisition and release of multiple permits at once, but this primitive does not offer that capability.</p>

<!-- end doc -->

</body></html>
